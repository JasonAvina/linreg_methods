# Benchmarking Regression Models on the Diabetes Dataset

This project compares several regression approaches to predict disease progression using the diabetes dataset from scikit-learn. It evaluates both linear and nonlinear models, with an emphasis on regularization and model complexity.

## 🔍 Models Implemented

- **Linear Regression** – Ordinary Least Squares
- **Ridge Regression** – L2 regularization
- **Lasso Regression** – L1 regularization
- **Elastic Net** – Combination of L1 and L2 regularization
- **K-Nearest Neighbors (KNN) Regression** – Non-parametric method
- **Random Forest Regression** – Tree-based ensemble method

## 🎯 Project Goals

- Predict disease progression using clinical variables
- Compare model performance using metrics such as RMSE, MAE, and R²
- Visualize coefficient shrinkage in Lasso, Ridge, and Elastic Net
- Assess model generalization on test data
- Demonstrate strengths and limitations of nonlinear and ensemble methods

## 📁 Files

- `diabetes_final_code.ipynb` — Main Jupyter Notebook containing all preprocessing, model training, evaluation, and visualizations.

## 💬 Notes

This project was developed in Google Colab using Python libraries including:
- `pandas`, `numpy` – Data handling
- `matplotlib`, `seaborn` – Visualizations
- `scikit-learn` – Model implementation and evaluation

> Some code and text were developed with the assistance of ChatGPT for clarity and efficiency.

## 📈 Example Output

(Metrics and charts can be added here later, or replaced with screenshots.)

## 🔗 Coming Soon

This project will be featured with a visual summary on my [GitHub Pages portfolio site](https://jasonavina.github.io).


