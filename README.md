# Benchmarking Regression Models on the Diabetes Dataset

This project compares several regression approaches to predict disease progression using the diabetes dataset from scikit-learn. It evaluates both linear and nonlinear models, with an emphasis on regularization and model complexity.

## ðŸ” Models Implemented

- **Linear Regression** â€“ Ordinary Least Squares
- **Ridge Regression** â€“ L2 regularization
- **Lasso Regression** â€“ L1 regularization
- **Elastic Net** â€“ Combination of L1 and L2 regularization
- **K-Nearest Neighbors (KNN) Regression** â€“ Non-parametric method
- **Random Forest Regression** â€“ Tree-based ensemble method

## ðŸŽ¯ Project Goals

- Predict disease progression using clinical variables
- Compare model performance using metrics such as RMSE, MAE, and RÂ²
- Visualize coefficient shrinkage in Lasso, Ridge, and Elastic Net
- Assess model generalization on test data
- Demonstrate strengths and limitations of nonlinear and ensemble methods

## ðŸ“ Files

- `diabetes_final_code.ipynb` â€” Main Jupyter Notebook containing all preprocessing, model training, evaluation, and visualizations.

## ðŸ’¬ Notes

This project was developed in Google Colab using Python libraries including:
- `pandas`, `numpy` â€“ Data handling
- `matplotlib`, `seaborn` â€“ Visualizations
- `scikit-learn` â€“ Model implementation and evaluation

> Some code and text were developed with the assistance of ChatGPT for clarity and efficiency.

## ðŸ“ˆ Example Output

(Metrics and charts can be added here later, or replaced with screenshots.)

## ðŸ”— Coming Soon

This project will be featured with a visual summary on my [GitHub Pages portfolio site](https://jasonavina.github.io).


